{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tabulate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** baseline results LOADED from ../results/custom_execution_baseline_results_20250127_A_2000_episodes.pkl *****\n"
     ]
    }
   ],
   "source": [
    "date_time_id = '20250127_A_2000_episodes'\n",
    "\n",
    "file_path = '../results/custom_execution_baseline_results_{}.pkl'.format(date_time_id)\n",
    "with open(file_path, 'rb') as fin:        \n",
    "    baseline_results_dict = pickle.load(fin)\n",
    "    print(f\"***** baseline results LOADED from {file_path} *****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mean       Std    Median    Mean terminal    Std terminal    Min terminal    Max terminal\n",
      "  reward    reward    reward        inventory       inventory       inventory       inventory\n",
      "--------  --------  --------  ---------------  --------------  --------------  --------------\n",
      "-0.08440   0.07359  -0.06188         -0.21650        13.09514             -24              25\n"
     ]
    }
   ],
   "source": [
    "baseline_stats = []\n",
    "baseline_stats.append(np.mean(baseline_results_dict['rewards'])) # mean reward\n",
    "baseline_stats.append(np.std(baseline_results_dict['rewards'])) # std reward\n",
    "baseline_stats.append(np.median(baseline_results_dict['rewards'])) # median reward\n",
    "baseline_stats.append(np.mean(baseline_results_dict['terminal_inventories'])) # mean terminal inventory\n",
    "baseline_stats.append(np.std(baseline_results_dict['terminal_inventories'])) # std terminal inventory\n",
    "baseline_stats.append(int(np.min(baseline_results_dict['terminal_inventories']))) # min terminal inventory\n",
    "baseline_stats.append(int(np.max(baseline_results_dict['terminal_inventories']))) # max terminal inventory\n",
    "\n",
    "cols = [\n",
    "    'Mean\\nreward', 'Std\\nreward', 'Median\\nreward','Mean terminal\\ninventory', \n",
    "    'Std terminal\\ninventory', 'Min terminal\\ninventory', 'Max terminal\\ninventory' \n",
    "]    \n",
    "print(tabulate.tabulate([baseline_stats], headers=cols, floatfmt='.5f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time_id = '20250127_A_@3000_for_2000'\n",
    "\n",
    "file_path = '../results/custom_execution_test_results_{}.pkl'.format(date_time_id)\n",
    "with open(file_path, 'rb') as fin:        \n",
    "    test_results_dict, _ = pickle.load(fin)\n",
    "    print(f\"***** test results LOADED from {file_path} *****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigate rewards\n",
    "\n",
    "Judging from histogram and boxplot plots, the distribution of the negative episode rewards may be estimated by a three parameter log-normal distribution with parameters shape, loc, scale. We say $X\\sim \\text{log-normal}(\\mu, \\sigma^2, \\delta)$, with the parameters $\\mu\\in\\mathbb{R}, \\sigma > 0$, and location parameter $\\delta\\in\\mathbb{R}$, if $ln(X-\\delta) \\sim \\mathcal{N}(\\mu, \\sigma^2)$. The transformed random variable $Y:= \\ln(X - \\delta)/\\sigma$ has standard normal distribution. Applying this transformation to the data set of negative episode reward with the fitted parameters we can test for normality.\n",
    "\n",
    "**Note:** The `scipy`function `stats.lognorm.fit` fits a three parameter log-normal distribution to a given data set, but returns the values `(shape, loc, scale)` with `shape` $=\\sigma$, `loc` $=\\delta$, and `scale` $=\\exp(\\mu)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram and boxplot\n",
    "rewards = np.array(baseline_results_dict['rewards'])\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9,4))\n",
    "axs[0].hist(rewards, bins=100, density=False)\n",
    "axs[1].boxplot(rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit 3 parameter log-normal\n",
    "\n",
    "We fit a three parameter log-normal distrbution to the data $\\{R_n\\}_{n=1,\\dots,3000}$ with $R_n$ the total reward obtained in episode $n$. With the obtained values `(shape, loc, scale)` we transform the data to normal.\n",
    "\n",
    "With location parameter estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780125293821907 -0.0016901585288279608 0.063883025477181\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy Anderson: AndersonResult(statistic=0.4499528021528931, critical_values=array([0.575, 0.655, 0.785, 0.916, 1.09 ]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]))\n",
      "scipy Shapiro: ShapiroResult(statistic=0.9989356398582458, pvalue=0.2767109274864197)\n",
      "scipy normaltest: NormaltestResult(statistic=3.095720835653119, pvalue=0.21270258197020553)\n",
      "scipy Jarque-Bera: Jarque_beraResult(statistic=2.8635456582064873, pvalue=0.23888504426436197)\n",
      "stats Anderson: (0.4499528021528931, 0.2758294857210485)\n",
      "stats Jarque-Bera: (2.8635456582064873, 0.23888504426436194, -0.03683550633788142, 2.8298967084686324)\n"
     ]
    }
   ],
   "source": [
    "rewards = np.array(np.array(baseline_results_dict['rewards']))\n",
    "shape, loc, scale  = stats.lognorm.fit(-rewards, method='MLE')\n",
    "lognorm_params = (shape, loc, scale)\n",
    "print(shape, loc, scale)\n",
    "#plt.boxplot(np.log(-np.array(baseline_results_dict[0]['rewards'])))\n",
    "#plt.show()\n",
    "\n",
    "# some tests need standardization\n",
    "stdized_rewards = (np.log(-rewards - loc) - np.log(scale)) / shape\n",
    "plt.hist(stdized_rewards, bins=50, density=False)\n",
    "plt.show()\n",
    "\n",
    "print('scipy Anderson:', stats.anderson(stdized_rewards))\n",
    "print('scipy Shapiro:', stats.shapiro(stdized_rewards,))\n",
    "print('scipy normaltest:', stats.normaltest(stdized_rewards))\n",
    "print('scipy Jarque-Bera:', stats.jarque_bera(stdized_rewards))\n",
    "print('stats Anderson:', sm.stats.diagnostic.normal_ad(stdized_rewards))\n",
    "print('stats Jarque-Bera:', sm.stats.stattools.jarque_bera(stdized_rewards))\n",
    "# jarque_bera only works for n > 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare histograms and boxplots for data and fitted lognormal distribution\n",
    "x = stats.lognorm.rvs(shape, loc=loc, scale=scale, size=len(rewards))\n",
    "plt.hist(np.array(baseline_results_dict['rewards']), bins=100, density=True, label='rewards')\n",
    "plt.hist(-x, bins=100, density=True, label='lognorm', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.boxplot([-x, baseline_results_dict['rewards']])\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9,4))\n",
    "stats.probplot(stdized_rewards, dist='norm', plot=axs[0])\n",
    "stats.probplot(-rewards, dist=stats.lognorm, sparams=lognorm_params, plot=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gof-tests with parametric bootstrapping\n",
    "Calculate critical values for some tests using parametric bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy Anderson: AndersonResult(statistic=0.4503475614783383, critical_values=array([0.575, 0.655, 0.785, 0.916, 1.09 ]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]))\n",
      "scipy Shapiro: ShapiroResult(statistic=0.9989323616027832, pvalue=0.27412962913513184)\n",
      "scipy KS: KstestResult(statistic=0.014498610118329258, pvalue=0.7887881553076839)\n",
      "AD 90.0%: 0.5713252508710411\n",
      "AD p-value: 0.215\n",
      "Shapiro 90.0%: 0.9995489895343781\n",
      "Shapiro p-value: 0.136\n",
      "KS 90.0%: 0.017826444670116626\n",
      "KS p-value: 0.336\n"
     ]
    }
   ],
   "source": [
    "rewards = np.array(baseline_results_dict['rewards'])\n",
    "n = len(rewards)\n",
    "\n",
    "# fit lognormal distribution\n",
    "shape, loc, scale = stats.lognorm.fit(-rewards, loc=0.0)\n",
    "stdized_rewards = (np.log(-rewards - loc) - np.log(scale)) / shape\n",
    "\n",
    "# calculate test statistics for negative rewards\n",
    "print(stats.anderson(stdized_rewards))\n",
    "print(stats.shapiro(stdized_rewards))\n",
    "print(stats.kstest(-rewards, stats.lognorm.cdf, args=(shape, loc, scale)))\n",
    "stat_anderson = stats.anderson(stdized_rewards)\n",
    "stat_shapiro = stats.shapiro(stdized_rewards)\n",
    "stat_ks = stats.kstest(-rewards, stats.lognorm.cdf, args=(shape, loc, scale))\n",
    "\n",
    "# generate bootstrap samples\n",
    "bootstrap_samples = stats.lognorm.rvs(shape, loc=loc, scale=scale, size=(1000, n))\n",
    "bootstrap_AD = []\n",
    "bootstrap_Shapiro = []\n",
    "bootstrap_KS = []\n",
    "# calculate test statistics for each bootstrap sample\n",
    "for sample in bootstrap_samples:\n",
    "    s_shape, s_loc, s_scale = stats.lognorm.fit(sample, loc=0.0)\n",
    "    stdzd_sample = (np.log(sample - s_loc) - np.log(s_scale)) / s_shape\n",
    "    bootstrap_AD.append(stats.anderson(stdzd_sample, dist='norm')[0])\n",
    "    bootstrap_Shapiro.append(stats.shapiro(stdzd_sample)[0])\n",
    "    bootstrap_KS.append(stats.kstest(sample, stats.lognorm.cdf, args=(s_shape, s_loc, s_scale))[0])\n",
    "\n",
    "# calculate critical values and p-values\n",
    "tst_lvl = 90.0\n",
    "print('\\nbootstrap results:')\n",
    "print(f'AD {tst_lvl}%:', np.percentile(np.array(bootstrap_AD), tst_lvl))\n",
    "print('AD p-value:', np.mean(np.array(bootstrap_AD) > stat_anderson[0]))\n",
    "print(f'Shapiro {tst_lvl}%:', np.percentile(np.array(bootstrap_Shapiro), tst_lvl))\n",
    "print('Shapiro p-value:', np.mean(np.array(bootstrap_Shapiro) < stat_shapiro[0]))\n",
    "print(f'KS {tst_lvl}%:', np.percentile(np.array(bootstrap_KS), tst_lvl)) \n",
    "print('KS p-value:', np.mean(np.array(bootstrap_KS) > stat_ks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confidence intervals\n",
    "\n",
    "### based on large sample theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array(baseline_results_dict['rewards'])\n",
    "n = len(rewards)\n",
    "z = stats.norm.ppf(0.975, loc=0, scale=1)\n",
    "mean = np.mean(rewards)\n",
    "std = np.std(rewards)\n",
    "sem = stats.sem(rewards, ddof=0)\n",
    "print(sem == std/np.sqrt(len(rewards)))\n",
    "\n",
    "CI_large_sample = stats.norm.interval(0.95, loc=mean, scale=sem)\n",
    "print(CI_large_sample)\n",
    "# same as\n",
    "#print((mean - z * std / np.sqrt(n), mean + z * std / np.sqrt(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### based on log-normal fit\n",
    "assuming non-zero loc from lognormal fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array(baseline_results_dict['rewards'])\n",
    "shape, loc, scale = stats.lognorm.fit(-rewards, loc=0.0)\n",
    "print(shape, loc, scale)\n",
    "\n",
    "t = stats.t.ppf(0.975, df=1, loc=0, scale=1)\n",
    "mean_log_neg_r = np.log(scale) # mean of (-R - loc), i.e. lognormal with location 0\n",
    "std_estimate = np.sqrt(shape ** 2 / n + shape ** 4 / (2*(n - 1)))\n",
    "\n",
    "CI_neg_r_wo_loc = (np.exp(mean_log_neg_r + shape ** 2 / 2 - t * std_estimate), \n",
    "                   np.exp(mean_log_neg_r + shape ** 2 / 2 + t * std_estimate))\n",
    "CI_neg_r_w_loc = (CI_neg_r_wo_loc[0] + loc, CI_neg_r_wo_loc[1] + loc)\n",
    "CI_r_w_loc = (-CI_neg_r_w_loc[1], -CI_neg_r_w_loc[0])\n",
    "print(CI_r_w_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### based on Olssen paper\n",
    "assuming loc=0 for log normal fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array(baseline_results_dict['rewards'])\n",
    "n = len(rewards)\n",
    "t = stats.t.ppf(0.975, df=2000, loc=0, scale=1)\n",
    "\n",
    "mean_log_neg_r = np.log(-rewards).mean()\n",
    "std_log_neg_r = np.log(-rewards).std()\n",
    "std_estimate = np.sqrt(std_log_neg_r ** 2 / n + std_log_neg_r ** 4 / (2*(n - 1)))\n",
    "\n",
    "CI_log_r = (np.exp(mean_log_neg_r + std_log_neg_r ** 2 / 2 - t * std_estimate), \n",
    "            np.exp(mean_log_neg_r + std_log_neg_r ** 2 / 2 + t * std_estimate))\n",
    "CI_log_r = (-CI_log_r[1], -CI_log_r[0])\n",
    "print(CI_log_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../results/lognormaldata.pkl'\n",
    "with open(file_path, 'wb') as fout:  \n",
    "    pickle.dump(-np.array(baseline_results_dict['rewards']), fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparison of results:\n",
    "\n",
    "**Intervals**\n",
    "- for first 2000 episode sample\n",
    "\n",
    "        large sample CI =   (-0.087628, -0.081177)  -0.006451  \n",
    "        lognorm fit CI =    (-0.088366, -0.081597)  -0.006769\n",
    "        Olssen CI =         (-0.089045, -0.082041)  -0.007004\n",
    "\n",
    "- for second 2000 episode sample\n",
    "\n",
    "        large sample CI =   (-0.090476, -0.083226)  -0.007250 \n",
    "        lognorm fit CI =    (-0.090564, -0.083312)  -0.007252\n",
    "        Olssen CI =         (-0.091417, -0.083886)  -0.007531\n",
    "\n",
    "- for third 2000 episode sample\n",
    "\n",
    "        large sample CI =   (-0.092140, -0.085115)  -0.007025\n",
    "        lognorm fit CI =    (-0.092574, -0.085305)  -0.007269\n",
    "        Olssen CI =         (-0.093780, -0.086114)  -0.007666\n",
    "\n",
    "**Fit**\n",
    "- with first 2000 episodes sample\n",
    "log normal fit: 0.7800772923280497 -0.001695245289439037 0.06388987175054339\n",
    "\n",
    "- with second 2000 episodes sample\n",
    "log normal fit:0.8107304974736751 -0.0015869911420958009 0.06367581684058965\n",
    "\n",
    "- for third 2000 episode sample\n",
    "0.7921070674008809 -0.0024017647583191902 0.06669789989475025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mid price changes\n",
    "Investige mean and maximal mid price changes to estimate rewards distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mid price changes in test results\n",
    "\n",
    "total_episodes = 20000\n",
    "total_steps = total_episodes * 180\n",
    "\n",
    "mp_changes = {}\n",
    "mp_changes_means = {}\n",
    "mp_changes_maxs = {}\n",
    "\n",
    "for run, test_run in test_results_dict.items():\n",
    "    mp_changes[run] = [\n",
    "        abs(np.array(mp[1:]) - np.array(mp[:-1]))\n",
    "        for mp in test_run['mid_prices']\n",
    "    ]\n",
    "    mp_changes_means[run] = [mp_changes.mean() for mp_changes in mp_changes[run]]\n",
    "    mp_changes_maxs[run] = [mp_changes.max() for mp_changes in mp_changes[run]]\n",
    "\n",
    "mo_means = {key: np.mean(means) for key, means in mp_changes_means.items()}\n",
    "mo_maxs = {key: np.mean(maxs) for key, maxs in mp_changes_maxs.items()}\n",
    "mo_means['momo_means'] = np.mean(list(mo_means.values()))\n",
    "mo_maxs['momo_maxs'] = np.mean(list(mo_maxs.values()))\n",
    "print(tabulate.tabulate(mo_means.items(), headers=['Run', 'Mean of mean mid-price changes']))\n",
    "print(tabulate.tabulate(mo_maxs.items(), headers=['Run', 'Mean of max mid-price changes']))\n",
    "\n",
    "\"\"\"\n",
    "for means, maxs in zip(mp_changes_means.values(), mp_changes_maxs.values()):\n",
    "    plt.hist(means, bins=100)\n",
    "    plt.show()\n",
    "    plt.hist(maxs, bins=100)\n",
    "    plt.show()\n",
    "\"\"\"    \n",
    "\n",
    "assumed_max_change = 34 #mo_maxs['momo_maxs']\n",
    "assumed_min_change = mo_means['momo_means']\n",
    "max_episode_reward = (assumed_max_change/100 * 180 + 0.7) * (25/1000) ** 2 \\\n",
    "    - sum([ ((700 - i * 50) / 1000) **  2 for i in range(15)]) * assumed_min_change/100\n",
    "print('maximal episode reward:', max_episode_reward)\n",
    "print(\n",
    "    f'pct of total mid price changes larger {assumed_max_change}:', \n",
    "    sum([sum(np.array(episode)>assumed_max_change) for run in mp_changes.values() for episode in run]) / total_steps\n",
    ")\n",
    "print(\n",
    "    f'pct of max mid price changes larger {assumed_max_change}:', \n",
    "    sum([sum(np.array(maxs) > assumed_max_change) for maxs in mp_changes_maxs.values()]) / total_episodes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape, loc, scale = 0.8, -0.3, 0.1\n",
    "samples = stats.lognorm.rvs(shape, loc=loc, scale=scale, size=2000)\n",
    "#plt.hist(samples, bins=100)\n",
    "#plt.show()\n",
    "stats.probplot(samples, dist='lognorm', sparams=(shape, loc, scale), plot=plt)\n",
    "plt.show()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9,4))\n",
    "#stats.probplot((np.log(samples - loc) -  np.log(shape))/scale, dist='norm', plot=axs[0])\n",
    "stats.probplot((np.log(samples - loc) -  np.log(scale))/shape, dist='norm', plot=axs[1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
